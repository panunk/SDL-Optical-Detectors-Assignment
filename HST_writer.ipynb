{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qYFWPwdyaj7",
        "outputId": "1a509315-1ca8-4bc9-99be-0608409b21d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting hst_HRDiagram.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile hst_HRDiagram.py\n",
        "\n",
        "def main():\n",
        "  \"\"\"\n",
        "    Takes HST Image and returns H-R Diagram of stars in the image and\n",
        "    a .txt file of a star catalog\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Input: Run the file in the right directory with all the relevant data\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    Output: Hopefully, an H-R Diagram and a .txt file with a star catalog\n",
        "    \"\"\"\n",
        "\n",
        "  ## Load Image Data\n",
        "  from astropy.io import fits\n",
        "\n",
        "  # Want to load image data and immediately convert it to flux\n",
        "  def convert_to_flux(filename):\n",
        "    \"\"\"\n",
        "    Converts image data to flux by either multiplying data with the inverse\n",
        "    sensitivity of the sensor [PHOTFLAM] or by dividing the data by its\n",
        "    exposure time.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Input: Filename of image data, must be .fits format\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    Output: Image data as flux (flux_data) and data header (header)\n",
        "    \"\"\"\n",
        "    with fits.open(filename) as hdul:\n",
        "      header = hdul[0].header\n",
        "      data_header = hdul[1].header # header data we want is weirdly in with the data\n",
        "      data = hdul[1].data\n",
        "\n",
        "    # Global Background Removal\n",
        "    # Note: Looking for helpful things in the data_header I found BACKGRND,\n",
        "    #       an estimated background level. Thank you HST!\n",
        "    data = data - data_header['BACKGRND']\n",
        "\n",
        "    # If BUNIT is COUNTS we have to convert to cps before we multiply PHOTFLAM\n",
        "    if data_header['BUNIT'].strip() == 'COUNTS':\n",
        "      flux_data = (data / header['EXPTIME']) * data_header['PHOTFLAM']\n",
        "\n",
        "    else:\n",
        "      flux_data = data * data_header['PHOTFLAM']\n",
        "\n",
        "    return flux_data, header\n",
        "\n",
        "  #F336W Filter Images\n",
        "  img1_336_data, img1_336_head = convert_to_flux('ubai2505m_c0m_aligned.fits')\n",
        "  img2_336_data, img2_336_head = convert_to_flux('ubai2507m_c0m_aligned.fits')\n",
        "  img3_336_data, img3_336_head = convert_to_flux('ubai2508m_c0m_aligned.fits')\n",
        "\n",
        "  #F555W Filter Images\n",
        "  img1_555_data, img1_555_head = convert_to_flux('ubai2502m_c0m_aligned.fits')\n",
        "  img2_555_data, img2_555_head = convert_to_flux('ubai2503m_c0m_aligned.fits')\n",
        "  img3_555_data, img3_555_head = convert_to_flux('ubai2504m_c0m_aligned.fits')\n",
        "\n",
        "  ## Cosmic Ray Removal\n",
        "  import numpy as np\n",
        "\n",
        "  # Remove Cosmic Rays by creating a median image of each Filter\n",
        "\n",
        "  #F336W Filter Median\n",
        "  median_336 = np.median(([img1_336_data, img2_336_data, img3_336_data]), axis=0)\n",
        "\n",
        "  #F555W Filter Median\n",
        "  median_555 = np.median(([img1_555_data, img2_555_data, img3_555_data]), axis=0)\n",
        "\n",
        "  ## Find Bright Sources\n",
        "  import scipy.ndimage as ndi\n",
        "\n",
        "  # Appyling a gaussian filter to smooth the data\n",
        "  smoothed336_data = ndi.gaussian_filter(median_336, sigma=0.5, mode='reflect')\n",
        "  smoothed555_data = ndi.gaussian_filter(median_555, sigma=0.5, mode='reflect')\n",
        "\n",
        "  # Get x,y coordinates of Peaks\n",
        "  def find_local_peaks(data, nsize=10):\n",
        "    \"\"\"\n",
        "    Uses a maximum filter to find peaks in the data. From class notes:\n",
        "    hst-worbook-03.ipynb.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    Input: Data [ndarray] and neighborhood size (nsize) of filter [int]\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    Output: Coordinates of peaks in data [ndarray]\n",
        "    \"\"\"\n",
        "    local_max = ndi.maximum_filter(data, size = nsize)\n",
        "\n",
        "    # turn the filter into a boolean mask where peaks are `True`\n",
        "    local_max_mask = (local_max == data)\n",
        "\n",
        "    # Not using a threshhold cause then my peak ciount would be too low\n",
        "    #threshold = 2 * np.std(data)\n",
        "    #threshold_mask = local_max_mask & (data> threshold)\n",
        "\n",
        "    #print the coordinates\n",
        "    coordinates = np.argwhere(local_max_mask)\n",
        "    #coordinates = np.argwhere(threshold_mask)\n",
        "\n",
        "    return coordinates\n",
        "\n",
        "  # Finding Peak Coords on Smoothed Images\n",
        "  smoothed336_coords = find_local_peaks(smoothed336_data)\n",
        "  smoothed555_coords = find_local_peaks(smoothed555_data)\n",
        "\n",
        "  # Note: 336 picks up way more peaks than 555, hopefully we can eliminate some\n",
        "\n",
        "  # Finding Peak Coords\n",
        "  peak336_coords = find_local_peaks(median_336)\n",
        "  peak555_coords = find_local_peaks(median_555)\n",
        "\n",
        "  # Note: Without smoothing, find_local_peaks find about 100 more peaks\n",
        "  # Note: Increasing neighborhood size decreases # of peaks found, will stick with 10\n",
        "\n",
        "  # Functions I'll Need for the Next Steps\n",
        "  from scipy.optimize import curve_fit\n",
        "\n",
        "  # Circular Aperture function\n",
        "  from re import X\n",
        "  def circular_aperture(data, center, radius):\n",
        "    \"\"\"\n",
        "    Extract a circular cutout from the input data.\n",
        "    From class notes: hst-worbook-03-worked.ipynb.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : `np.ndarray`\n",
        "      the input data\n",
        "    center : list or tuple\n",
        "      the center of the circle to extract, in y-x order\n",
        "    radius : int or float\n",
        "      the radius of the circle in pixels\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    cutout : `np.ndarray`\n",
        "      a square cutout of the data\n",
        "    mask : `np.ndarray`\n",
        "      the circular mask used for the operation\n",
        "    \"\"\"\n",
        "\n",
        "    box_size = int(np.ceil(2*radius))\n",
        "    cutout = cutils.square_aperture(data, center=center, box_size = box_size)\n",
        "\n",
        "    ys, xs = np.indices(cutout.shape) #making an index of our pixels\n",
        "\n",
        "    # get new center of cutout\n",
        "    xc = cutout.shape[1] // 2 #// integer division no remainder\n",
        "    yc = cutout.shape[0] // 2\n",
        "\n",
        "    # get pixel start position for mask\n",
        "    y0 = yc - box_size // 2\n",
        "    x0 = xc - box_size // 2\n",
        "\n",
        "    # now get index coords\n",
        "    x_coords = xs + x0\n",
        "    y_coords = ys + y0\n",
        "\n",
        "    # get distance from center for all these mask pixel values\n",
        "    distance = np.sqrt((x_coords - xc)**2 + (y_coords - yc)**2)\n",
        "\n",
        "    # define mask as true for all values inside circle R\n",
        "    mask = distance <= radius\n",
        "\n",
        "    return cutout, mask\n",
        "\n",
        "  # Gaussian 2d Function\n",
        "  def gaus_2d(coords, amp, x0, y0, sigma_x, sigma_y):\n",
        "    \"\"\"\n",
        "    A simple 2D gaussian function\n",
        "    From class notes: hst-worbook-03-worked.ipynb.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    coords : list-like\n",
        "      the (y, x) coordinates to evaluate\n",
        "    amp : float\n",
        "      the amplitude of the gaussian\n",
        "    x0 : float\n",
        "      the mean value in x\n",
        "    y0 : float\n",
        "      the mean value in y\n",
        "    sigx : float\n",
        "      the sigma in x\n",
        "    sigy : float\n",
        "      the sigma in y\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    res : array-like\n",
        "      the evaluated function as a raveled array\n",
        "    \"\"\"\n",
        "    y, x = coords\n",
        "\n",
        "    gauss = amp * np.exp(\n",
        "        -(((x-x0)**2/(2*sigma_x)**2) + ((y-y0)**2 / (2*sigma_y)**2))\n",
        "    )\n",
        "\n",
        "    return gauss.ravel()\n",
        "\n",
        "  # Gaussian 2d Fit Function\n",
        "  def fit_gauss2d(data, p0=None):\n",
        "    \"\"\"\n",
        "    Fit a gaussian given data and some initial parameters\n",
        "    From class notes: hst-worbook-03.ipynb.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data : np.ndarray\n",
        "      the data to fit\n",
        "    init_par : list or None\n",
        "      the initial parameters. if None, estimate\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    popt : np.ndarray\n",
        "      the optimized parameters of the fit\n",
        "    pcov : np.ndarray\n",
        "      the covariance matrix of the fit\n",
        "    \"\"\"\n",
        "\n",
        "    if p0 is None:  # a nice guess for p0 so curve_fit isn't taking a long time\n",
        "      a0 = data.max() - data.min()\n",
        "      x0 = data.shape[1] / 2\n",
        "      y0 = data.shape[0] / 2\n",
        "      sigx0 = 0.5\n",
        "      sigy0 = 0.5\n",
        "      p0 = [a0, x0, y0, sigx0, sigy0]\n",
        "\n",
        "    y, x = np.indices(data.shape)\n",
        "\n",
        "    popt, pcov = curve_fit(gaus_2d, (y,x), data.ravel(), p0 = p0)\n",
        "\n",
        "    return popt, pcov\n",
        "\n",
        "  ## Classifying Sources as Stars\n",
        "\n",
        "  def star_finder(star_data, coords):\n",
        "    \"\"\"\n",
        "    Function to find sources that are likely stars and add them to a catalog\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    coords : list-like\n",
        "      the (y, x) coordinates to evaluate\n",
        "    star_data : array-like\n",
        "      the image data\n",
        "\n",
        "    Returns:\n",
        "    -----------\n",
        "    star_catalog : dictionary\n",
        "      the final catalog of star sources with their index, locations, fluxes, and\n",
        "      absolute magnitudes\n",
        "    \"\"\"\n",
        "    from scipy.optimize import curve_fit\n",
        "\n",
        "    # Create a Star Catalog (Dictionary)\n",
        "    star_catalog = {\n",
        "    'OBJECT': [],\n",
        "    'XY COORD': [],\n",
        "    'FLUX' : [],\n",
        "    'ABS MAG': []\n",
        "    }\n",
        "\n",
        "    # Star Classification Loop:\n",
        "    # - loop through coordinates of peaks\n",
        "    # - take a circular cutout of source\n",
        "    # - find if source is too flat or neg flux or wide\n",
        "    # - if source passes, sum flux and add to dictionary\n",
        "\n",
        "    # Index for my catalog\n",
        "    star_count = 1\n",
        "\n",
        "    # Figuring out my issue\n",
        "    cutout_wrong = 0\n",
        "    curvefit_wrong = 0\n",
        "\n",
        "    for coord in coords:\n",
        "\n",
        "      # Create Cutout around Source\n",
        "      # Note: using a circular aperture to decrease source overlap\n",
        "\n",
        "      # circular_aperture is not happy when my coordinate values are less than my radius\n",
        "      # so I'll filter out those coordinates\n",
        "      if coord[0] > 4 and coord[1] > 4:\n",
        "        cutout, mask = circular_aperture(star_data, center = coord.T, radius = 4)\n",
        "      else:\n",
        "        cutout_wrong += 1\n",
        "        continue #pretty sure it'll skip to new loop iteration and not do below code\n",
        "\n",
        "      # Do Gaussian fit of Source in Cutout\n",
        "      # - gives us info for flattening and width\n",
        "\n",
        "      # Some of my coord values are crashing curve_fit so I'll reject them as well\n",
        "      try:\n",
        "        popt, pcov = fit_gauss2d(cutout)\n",
        "      except:\n",
        "        curvefit_wrong += 1\n",
        "        continue\n",
        "\n",
        "      # Sum Flux of Source in Cutout\n",
        "      # Only want to sum flux within mask\n",
        "      masked_data = np.ma.masked_array(data = cutout, mask = ~mask)\n",
        "      source_flux = np.sum(masked_data)\n",
        "\n",
        "      # Find Source Magnitude\n",
        "      # Finding Absolute Magnitude\n",
        "      source_mag = -2.5 * np.log10(abs(source_flux)) - 48.60\n",
        "\n",
        "      # Create Star Filter\n",
        "      # Flattening cutoff\n",
        "      flatmax = .6\n",
        "      flattening = abs(1 - min(popt[3], popt[4]) / max(popt[3], popt[4]))\n",
        "\n",
        "      # Width cutoff\n",
        "      # WFPC2 has a pixel size of 0.046\"\n",
        "      # (Source: Wide Field and Planetary Camera 2 Instrument Handbook for Cycle 14)\n",
        "      # WFPC2's PSF function ranges from 0.02\" - 0.08\" depending on wavelength\n",
        "      # (Source: Google Gemini AI with harvard.edu sources BUT the sources didn't work when I tried them)\n",
        "      widthmax = 0.05\n",
        "      width = (abs(popt[1]-popt[2]))*0.046\n",
        "\n",
        "      if width <= widthmax and flattening <= flatmax and source_flux > 0:\n",
        "        # Add source to Star Catalog\n",
        "        star_catalog['OBJECT'].append(star_count)\n",
        "        star_catalog['XY COORD'].append(coord)\n",
        "        star_catalog['FLUX'].append(source_flux)\n",
        "        star_catalog['ABS MAG'].append(source_mag)\n",
        "\n",
        "        # Increase Star Counter\n",
        "        star_count += 1\n",
        "\n",
        "      else:\n",
        "        # We don't want this source\n",
        "        continue\n",
        "    print(cutout_wrong)\n",
        "    print(curvefit_wrong)\n",
        "    return star_catalog\n",
        "\n",
        "  # Find Stars in Images\n",
        "  star_cat336 = star_finder(smoothed336_data, smoothed336_coords)\n",
        "  star_cat555 = star_finder(smoothed555_data, smoothed555_coords)\n",
        "\n",
        "  ## Creating the H-R Diagram\n",
        "\n",
        "  # Combining the Catalogs\n",
        "  # Note: F336W found more stars than F555W\n",
        "\n",
        "  # Align by Coordinates:\n",
        "  # Remove Stars that don't occur in both catalogs\n",
        "  # So we can subtract their magnitudes for the HR Diagram\n",
        "\n",
        "  # Combining the Catalogs\n",
        "  # Note: F336W found more stars than F555W\n",
        "\n",
        "  # Create a new combined catalog\n",
        "  combined_catalog = {\n",
        "   'OBJECT': [],\n",
        "   'XY COORD': [],\n",
        "   'F336W FLUX' : [],\n",
        "   'F555W FLUX' : [],\n",
        "   'F336W ABS MAG': [],\n",
        "   'F555W ABS MAG': [],\n",
        "   'F336W - F555W': []\n",
        "  }\n",
        "\n",
        "\n",
        "  # Index for the combined catalog\n",
        "  combined_count = 1\n",
        "\n",
        "  ## Was helped by Gemini to create this loop below BUT\n",
        "  # Initially it only found direct matches (there's 43) and when I changed it\n",
        "  # to see if it could check one set of coords against all other coordinates,\n",
        "  # it took longer than five minutes and I canceled the run\n",
        "\n",
        "  # Loop through F336W Catalog\n",
        "  for i in range(len(star_cat336['OBJECT'])):\n",
        "    #coords_336 = star_cat336['XY COORD'][i]\n",
        "    flux_336 = star_cat336['FLUX'][i]\n",
        "    mag_336 = star_cat336['ABS MAG'][i]\n",
        "\n",
        "   # Check if the coords match in F555W Catalog\n",
        "    found_match = False\n",
        "\n",
        "  for j in range(len(star_cat555['OBJECT'])):\n",
        "    #coords_555 = star_cat555['XY COORD'][j]\n",
        "    if np.array_equal(star_cat555['XY COORD'][j], star_cat336['XY COORD']):\n",
        "      # Found a match, add to the combined catalog\n",
        "      combined_catalog['OBJECT'].append(combined_count)\n",
        "      combined_catalog['XY COORD'].append(coords_336)\n",
        "      combined_catalog['F336W FLUX'].append(flux_336)\n",
        "      combined_catalog['F555W FLUX'].append(star_cat555['FLUX'][j])\n",
        "      combined_catalog['F336W ABS MAG'].append(mag_336)\n",
        "      combined_catalog['F555W ABS MAG'].append(star_cat555['ABS MAG'][j])\n",
        "      combined_catalog['F336W - F555W'].append(mag_336 - star_cat555['ABS MAG'][j])\n",
        "\n",
        "      combined_count += 1\n",
        "      found_match = True\n",
        "      break # Exit the inner loop once a match is found\n",
        "\n",
        "    # If no match was found in F555W, this star is not included in the combined catalog\n",
        "    if not found_match:\n",
        "       continue\n",
        "\n",
        "  ## Create HR Diagram\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(5,5))\n",
        "  ax.scatter(combined_catalog['F336W - F555W'], combined_catalog['F336W ABS MAG'])\n",
        "\n",
        "  plt.title('H-R Diagram')\n",
        "  plt.xlabel('F336W - F555W')\n",
        "  plt.ylabel('F336W ABS MAG')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  ## Write Catalog to a file\n",
        "  f = open(\"combined_catalog.txt\", \"w\")\n",
        "  f.write(print(combined_catalog) + f.name)\n",
        "  f.close()\n",
        "\n",
        "# Make sure to run the main() function when I call the file in the command line\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ]
}